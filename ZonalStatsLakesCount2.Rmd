---
title: "LakesCount"
author: "rickD"
\e: "Thursday, July 09, 2015"
output: html_document
---

## Calculate point in polygon (count) results for dam points dataset and return in same table format as our zonal statistics for gridded datasets
```{r, cache=TRUE, eval=FALSE}
library(rgdal)
library(raster)
library(plyr)
library(dplyr)
library(foreign)
metric <- 'TRI'
metricFileName <- 'TRI'
metric_dir <- 'D:\\Projects\\lakesAnalysis\\MetricData'
out_dir <- "D:\\Projects\\lakesAnalysis\\Output\\Off-NetworkCatResults\\"
rgns <- c("NE","MA","SA","SA","SA","GL","MS","MS","MS","MS","SR","MS","MS","MS","TX","RG","CO","CO","GB","PN","CA")
names(rgns) <- c("01","02","03S","03N","03W","04","05","06","07","08","09","10L","10U","11","12","13","14","15","16","17","18")
zones <- c("01","02","03","04","05","06","07","08","09","10","11","12","13","14","15","16","17","18")
setwd('D:\\Projects\\lakesAnalysis\\NHDPlus_Lakes_Basins_Rasters')
wtshds <- list.files(path='.',pattern='_wtshds.tif')
wtshds <- wtshds[lapply(wtshds,function(x) length(grep("vat",x,value=FALSE))) == 0]
wtshds <- wtshds[lapply(wtshds,function(x) length(grep("xml",x,value=FALSE))) == 0]
points <- readOGR(metric_dir, layer = metricFileName)
#points$xalb <- coordinates(points)[,1]
#points$yalb <- coordinates(points)[,2]
#points <- points[!duplicated(points@data[,names(points) %in% c('xalb','yalb')]),]

for (j in zones){
zonalAll <- data.frame(cat_gridcode=NA,CatCount=NA)
wsAll <- data.frame(Value=NA,Count=NA,AREASQKM=NA)
wtshdzn <- wtshds[!lapply(wtshds,function(x) length(grep(j,x,value=FALSE))) == 0]
  for (k in wtshdzn){
    cat <- raster(k)
    crs(cat) <- "+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"
    points2 <- spTransform(points, CRS(projection(cat)))
    dam.gridcode2 = extract(cat,points2)
    points2$cat_gridcode <- dam.gridcode2  
    points2 <- points2[!is.na(points2$cat_gridcode),]
    # run using NormStor and another using NIDStor using sum instead of length: sum(NIDStorM3) ,  length(cat_gridcode) CatCount= sum(NrmStorM3)        
    zonal <- ddply(points2@data, "cat_gridcode", summarise,  CatCount = length(cat_gridcode))
    zonalAll  <- rbind(zonal,zonalAll) 
    cat.area <- read.dbf(paste(c("D:/Projects/lakesAnalysis/NHDPlus_Lakes_Basins_Rasters/reg",substr(k,4,6),"_wtshds.tif.vat.dbf"),collapse=''))
    cat.area$AREASQKM <- (cat.area$Count * 900) * 0.000001
    wsAll <- rbind(cat.area,wsAll)
  } 
wsAll <- group_by(wsAll, Value)
wsAll <- filter(wsAll, AREASQKM == max(AREASQKM))
wsAll <- filter(wsAll, row_number(Value) == 1)
zonalAll <- group_by(zonalAll, cat_gridcode)
zonalAll <- filter(zonalAll, CatCount == max(CatCount))
zonalAll <- filter(zonalAll, row_number(cat_gridcode) == 1)
results <- merge(wsAll[,c(1,3)],zonalAll, by.x="Value", by.y="cat_gridcode",all.x=T)
names(results)[1] <- c("COMID")
names(results)[2] <- c("CatAreaSqKm")
# Catchment mean storage is storage volume divided by catchment area
results$CatMean <- results$CatCount / results$CatAreaSqKm
results$CatPctFull <- 100
# set all NAs to zeros
results[is.na(results)] <- 0
#results <- results[c(1:3,9:10)]
write.csv(results, paste(c(out_dir,metric,'_cat',substr(k,4,5),".csv"),collapse=''), row.names=F)
cat("done with ",j)
  }
```
